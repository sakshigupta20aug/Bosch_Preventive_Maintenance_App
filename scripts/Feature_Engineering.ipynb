{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb5525d3-e402-45f3-927b-71968081ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numeric data...\n",
      "Loading date/time data...\n",
      "Loading categorical data...\n",
      "Converting Id columns to int64 for merging...\n",
      "Merging features...\n",
      "✅ Feature engineering complete! Saved: C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\\data\\processed\\bosch_clean.csv\n",
      "Processed dataset shape: (50000, 40)\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# FEATURE ENGINEERING - STANDALONE SCRIPT (Updated)\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "project_dir = Path(r\"C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\")\n",
    "data_dir = project_dir / \"data\" / \"bosch\"\n",
    "processed_dir = project_dir / \"data\" / \"processed\"\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "num_fp = data_dir / \"train_numeric.csv.zip\"\n",
    "date_fp = data_dir / \"train_date.csv.zip\"\n",
    "cat_fp = data_dir / \"train_categorical.csv.zip\"\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load numeric data & labels\n",
    "# -----------------------------\n",
    "print(\"Loading numeric data...\")\n",
    "num_df = pd.read_csv(num_fp, compression='zip', nrows=50000)  # adjust nrows for memory\n",
    "labels = num_df[[\"Id\", \"Response\"]].rename(columns={\"Response\": \"target\"})\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Compute cycle time from date data\n",
    "# -----------------------------\n",
    "print(\"Loading date/time data...\")\n",
    "date_df = pd.read_csv(date_fp, compression='zip', nrows=200000)  # adjust nrows\n",
    "date_cols = [c for c in date_df.columns if c != \"Id\"]\n",
    "date_min = date_df[date_cols].min(axis=1, skipna=True)\n",
    "date_max = date_df[date_cols].max(axis=1, skipna=True)\n",
    "cycle_time = (date_max - date_min).astype(\"float32\")\n",
    "date_features = pd.DataFrame({\"Id\": date_df[\"Id\"], \"cycle_time\": cycle_time})\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Compute station flags from categorical data\n",
    "# -----------------------------\n",
    "print(\"Loading categorical data...\")\n",
    "# Fix: treat all columns as string to avoid mixed type warnings\n",
    "cat_df = pd.read_csv(cat_fp, compression='zip', nrows=200000, dtype=str)\n",
    "\n",
    "station_flags = pd.DataFrame({\"Id\": cat_df[\"Id\"]})\n",
    "for col in cat_df.columns:\n",
    "    if col == \"Id\":\n",
    "        continue\n",
    "    parts = col.split(\"_\")\n",
    "    if len(parts) > 1:\n",
    "        station = parts[1]\n",
    "        flag_col = f\"flag_{station}\"\n",
    "        if flag_col not in station_flags.columns:\n",
    "            station_flags[flag_col] = 0\n",
    "        # mark 1 if any non-missing value exists\n",
    "        station_flags[flag_col] = station_flags[flag_col] | (~cat_df[col].isna()).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Numeric aggregates (mean, median, missing count)\n",
    "# -----------------------------\n",
    "agg_df = num_df.drop(columns=[\"Id\", \"Response\"], errors=\"ignore\")\n",
    "num_mean = agg_df.mean(axis=1, skipna=True)\n",
    "num_median = agg_df.median(axis=1, skipna=True)\n",
    "num_missing = agg_df.isna().sum(axis=1)\n",
    "\n",
    "numeric_agg = pd.DataFrame({\n",
    "    \"Id\": num_df[\"Id\"],\n",
    "    \"num_mean\": num_mean,\n",
    "    \"num_median\": num_median,\n",
    "    \"num_missing\": num_missing\n",
    "})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Merge everything\n",
    "# -----------------------------\n",
    "print(\"Converting Id columns to int64 for merging...\")\n",
    "labels[\"Id\"] = labels[\"Id\"].astype(\"int64\")\n",
    "date_features[\"Id\"] = date_features[\"Id\"].astype(\"int64\")\n",
    "station_flags[\"Id\"] = station_flags[\"Id\"].astype(\"int64\")\n",
    "numeric_agg[\"Id\"] = numeric_agg[\"Id\"].astype(\"int64\")\n",
    "\n",
    "print(\"Merging features...\")\n",
    "df = labels.merge(date_features, on=\"Id\", how=\"left\")\n",
    "df = df.merge(station_flags, on=\"Id\", how=\"left\")\n",
    "df = df.merge(numeric_agg, on=\"Id\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Save processed dataset\n",
    "# -----------------------------\n",
    "output_fp = processed_dir / \"bosch_clean.csv\"\n",
    "df.to_csv(output_fp, index=False)\n",
    "\n",
    "print(f\"✅ Feature engineering complete! Saved: {output_fp}\")\n",
    "print(\"Processed dataset shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55e8b2-222c-4941-badf-f8fcf1d58d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
