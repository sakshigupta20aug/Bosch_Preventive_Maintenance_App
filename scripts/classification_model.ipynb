{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810b7aa1-a104-4042-9e83-a9d0e42184fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "âœ… Data Loaded\n",
      "Shape: (50000, 40)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š MODEL EVALUATION RESULTS\n",
      "============================================================\n",
      "ROC AUC Score : 0.5614\n",
      "PR AUC Score  : 0.0110\n",
      "Positive Rate (test set): 0.5400%\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision  recall  f1-score     support\n",
      "0                0.9948  0.9484    0.9711   9946.0000\n",
      "1                0.0097  0.0926    0.0175     54.0000\n",
      "accuracy         0.9438  0.9438    0.9438      0.9438\n",
      "macro avg        0.5022  0.5205    0.4943  10000.0000\n",
      "weighted avg     0.9895  0.9438    0.9659  10000.0000\n",
      "\n",
      "--- Confusion Matrix (threshold=0.5) ---\n",
      "                 Pred 0 (Pass)  Pred 1 (Fail)\n",
      "Actual 0 (Pass)           9433            513\n",
      "Actual 1 (Fail)             49              5\n",
      "\n",
      "============================================================\n",
      "ðŸ“‚ Outputs Saved\n",
      "============================================================\n",
      "Model File   : C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\\models\\classification_model.pkl\n",
      "Metrics File : C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\\models\\classification_metrics.json\n",
      "Confusion Matrix Plot : C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\\reports\\figures\\confusion_matrix.png\n",
      "PR Curve Plot        : C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\\reports\\figures\\precision_recall_curve.png\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# scripts/classification_model.py\n",
    "\"\"\"\n",
    "Train classification model (XGBoost) on Bosch Preventive Maintenance sample.\n",
    "Evaluates with proper classification metrics (ROC AUC, PR AUC, confusion matrix, classification report).\n",
    "\"\"\"\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_recall_curve, classification_report,\n",
    "    confusion_matrix, auc\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------------------\n",
    "# Paths\n",
    "# -------------------\n",
    "PROJECT_DIR = Path(r\"C:\\Users\\Admin\\Downloads\\Internship\\Bosch_PMP\")\n",
    "PROC_FP = PROJECT_DIR / \"data\" / \"processed\" / \"bosch_clean.csv\"\n",
    "MODEL_DIR = PROJECT_DIR / \"models\"\n",
    "FIG_DIR = PROJECT_DIR / \"reports\" / \"figures\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# -------------------\n",
    "# Functions\n",
    "# -------------------\n",
    "\n",
    "def load_data(path):\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "def prepare_features(df):\n",
    "    if \"Id\" in df.columns:\n",
    "        df = df.drop(columns=[\"Id\"])\n",
    "    if \"Response\" in df.columns and \"target\" not in df.columns:\n",
    "        df = df.rename(columns={\"Response\": \"target\"})\n",
    "    y = df[\"target\"].astype(int)\n",
    "    X = df.drop(columns=[\"target\"])\n",
    "    X = X.select_dtypes(include=[np.number]).fillna(0)\n",
    "    return X, y\n",
    "\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    pos = y_train.sum()\n",
    "    neg = len(y_train) - pos\n",
    "    scale_pos_weight = (neg / (pos + 1e-9)) if pos > 0 else 1.0\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.6,\n",
    "        reg_lambda=1.0,\n",
    "        tree_method=\"hist\",\n",
    "        objective=\"binary:logistic\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric=\"auc\"\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Probabilities and predictions\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {}\n",
    "    metrics[\"roc_auc\"] = float(roc_auc_score(y_test, y_prob)) if len(np.unique(y_test)) > 1 else None\n",
    "\n",
    "    prec, rec, _ = precision_recall_curve(y_test, y_prob)\n",
    "    metrics[\"pr_auc\"] = float(auc(rec, prec))\n",
    "\n",
    "    metrics[\"classification_report\"] = classification_report(y_test, y_pred, digits=4, zero_division=0, output_dict=True)\n",
    "    metrics[\"confusion_matrix\"] = confusion_matrix(y_test, y_pred).tolist()\n",
    "    metrics[\"positive_rate_test\"] = float(y_test.mean())\n",
    "\n",
    "    return model, metrics, prec, rec\n",
    "\n",
    "def save_outputs(model, metrics, X_cols, prec, rec):\n",
    "    # Save model + metrics\n",
    "    joblib.dump(model, MODEL_DIR / \"classification_model.pkl\")\n",
    "    with open(MODEL_DIR / \"classification_metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    with open(MODEL_DIR / \"classification_features.txt\", \"w\") as f:\n",
    "        for c in X_cols:\n",
    "            f.write(c + \"\\n\")\n",
    "\n",
    "    # Confusion matrix plot\n",
    "    import seaborn as sns\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix (threshold=0.5)\")\n",
    "    plt.ylabel(\"Actual\"); plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"confusion_matrix.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Precision-Recall curve\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.step(rec, prec, where='post')\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall curve (AUC=%.4f)\" % metrics[\"pr_auc\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"precision_recall_curve.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------\n",
    "# Main\n",
    "# -------------------\n",
    "def main():\n",
    "    df = load_data(PROC_FP)\n",
    "    print(\"=\"*60)\n",
    "    print(\"âœ… Data Loaded\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    X, y = prepare_features(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    model, metrics, prec, rec = train_and_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š MODEL EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ROC AUC Score : {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC Score  : {metrics['pr_auc']:.4f}\")\n",
    "    print(f\"Positive Rate (test set): {metrics['positive_rate_test']:.4%}\")\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    report_df = pd.DataFrame(metrics[\"classification_report\"]).transpose()\n",
    "    print(report_df.round(4))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"\\n--- Confusion Matrix (threshold=0.5) ---\")\n",
    "    cm = np.array(metrics[\"confusion_matrix\"])\n",
    "    print(pd.DataFrame(\n",
    "        cm,\n",
    "        index=[\"Actual 0 (Pass)\", \"Actual 1 (Fail)\"],\n",
    "        columns=[\"Pred 0 (Pass)\", \"Pred 1 (Fail)\"]\n",
    "    ))\n",
    "\n",
    "    save_outputs(model, metrics, X.columns, prec, rec)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“‚ Outputs Saved\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model File   : {MODEL_DIR / 'classification_model.pkl'}\")\n",
    "    print(f\"Metrics File : {MODEL_DIR / 'classification_metrics.json'}\")\n",
    "    print(f\"Confusion Matrix Plot : {FIG_DIR / 'confusion_matrix.png'}\")\n",
    "    print(f\"PR Curve Plot        : {FIG_DIR / 'precision_recall_curve.png'}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
